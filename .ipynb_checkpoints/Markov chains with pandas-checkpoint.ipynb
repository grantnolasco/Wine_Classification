{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Pandas\n",
    "\n",
    "In this exercise we will be working with the `pandas` library, an essential tool for data wrangling with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` gives us two fundamental data structures: the `Series` and the `DataFrame`.\n",
    "\n",
    "### Series\n",
    "\n",
    "A `Series` is a sequence of values.  It is similar to a Python list in that you can access its elements by numerical index (using the `.iloc` accessor, as in `my_series.iloc[1]`), but it also allows labelled access somewhat like a Python dictionary (using the `.loc` accessor, as in `my_series.loc['blah']`).\n",
    "\n",
    "You can create a Series from a list easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.00\n",
       "1   -8.00\n",
       "2    8.80\n",
       "3    8.88\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = pandas.Series([8, -8, 8.8, 8.88])\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series can be iterated over similar to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "-8.0\n",
      "8.8\n",
      "8.88\n"
     ]
    }
   ],
   "source": [
    "for item in my_series:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels for a Series are called its `index`.  In that example we didn't provide any index, but we can do so with the `index` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     Sacramento\n",
       "Oregon              Salem\n",
       "Washington        Olympia\n",
       "Nevada        Carson City\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = pandas.Series(['Sacramento', 'Salem', 'Olympia', 'Carson City'], index=['California', 'Oregon', 'Washington', 'Nevada'])\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is like a set of labels that can be used to access individual elements from the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sacramento'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.loc['California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access elements using the positional index if we need to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olympia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can select ranges that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oregon          Salem\n",
       "Washington    Olympia\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that indexes start from 0, just like with regular Python lists, and, as with Python lists, the ending index is not included, so `iloc[1:3]` means 1 to 3, including 1 but not including 3.)\n",
    "\n",
    "In most cases, using label-based indexing is more convenient.  It is also often safer, since positional indexes can change if we transform the data, for instance by sorting.  But sometimes numerical indexing is useful to peek at random parts of the data without needing to know what the labels are.\n",
    "\n",
    "You can sort a series by its index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     Sacramento\n",
       "Nevada        Carson City\n",
       "Oregon              Salem\n",
       "Washington        Olympia\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". . . or by its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        Carson City\n",
       "Washington        Olympia\n",
       "California     Sacramento\n",
       "Oregon              Salem\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the sort is in ascending order (alphabetical order for strings, as we have here).  We can get the opposite order easily enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oregon              Salem\n",
       "California     Sacramento\n",
       "Washington        Olympia\n",
       "Nevada        Carson City\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these operations do not modify the original Series.  If we look at it, it will still be in its original order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     Sacramento\n",
       "Oregon              Salem\n",
       "Washington        Olympia\n",
       "Nevada        Carson City\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the sorting happen \"in place\" by passing the shockingly named `inplace` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        Carson City\n",
       "Washington        Olympia\n",
       "California     Sacramento\n",
       "Oregon              Salem\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.sort_values(inplace=True)\n",
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that after sorting, positional indexes will change (try doing `my_series.iloc[2]` again and compare to the result above) but pandas keeps the labels consistently attached to their values (compare `my_series.loc['California']`).\n",
    "\n",
    "A useful method on Series is `.map()`, which lets us give a function that will be applied to each element in the Series.  As an example, let's make a function that counts how many lowercase *a*s are in the city name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_a(name):\n",
    "    return name.count('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply it using `.map()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        1\n",
       "Washington    1\n",
       "California    2\n",
       "Oregon        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.map(count_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result is again a Series.\n",
    "\n",
    "We can apply any function we want.  However, we don't need to write functions for doing simple stuff like mathematical operations.  We can just do the operations directly on the Series and they'll apply to each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        4\n",
       "Washington    4\n",
       "California    5\n",
       "Oregon        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.map(count_a) + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with conditional expressions, to get a Series of True and False values telling us where the condition is true or false:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        False\n",
       "Washington    False\n",
       "California     True\n",
       "Oregon        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series == \"Sacramento\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we didn't need to even write the function we just wrote, since string methods are also available under the `.str` accessor.  So we could just do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevada        1\n",
       "Washington    1\n",
       "California    2\n",
       "Oregon        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series.str.count('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "A DataFrame is basically a table where each column is a Series.  DataFrames are a powerful tool for manipulating all kinds of tabular data.\n",
    "\n",
    "You can create one in various ways.  One way is to pass a dictionary of columns, where each key is a column name and each value is list of values for that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Capital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>Sacramento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>Salem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Olympia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>Carson City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State      Capital\n",
       "0  California   Sacramento\n",
       "1      Oregon        Salem\n",
       "2  Washington      Olympia\n",
       "3      Nevada  Carson City"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pandas.DataFrame({\"State\": [\"California\", \"Oregon\", \"Washington\", \"Nevada\"], \"Capital\": [\"Sacramento\", \"Salem\", \"Olympia\", \"Carson City\"]})\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the notebook gives us a nice tabular display of the DataFrame.  (Again, we could pass an index if we wanted to.)\n",
    "\n",
    "Another way to create a DataFrame is to use the `from_records` classmethod and pass a list of rows, where each row is a dictionary that has the column names as keys and the values as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capital</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salem</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olympia</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carson City</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Capital       State\n",
       "0   Sacramento  California\n",
       "1        Salem      Oregon\n",
       "2      Olympia  Washington\n",
       "3  Carson City      Nevada"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pandas.DataFrame.from_records([\n",
    "    {\"State\": \"California\", \"Capital\": \"Sacramento\"},\n",
    "    {\"State\": \"Oregon\", \"Capital\": \"Salem\"},\n",
    "    {\"State\": \"Washington\", \"Capital\": \"Olympia\"},\n",
    "    {\"State\": \"Nevada\", \"Capital\": \"Carson City\"},\n",
    "])\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you will instead be loading your DataFrame from a file.  We'll practice using the file `language_speakers.csv`, which contains a table cribbed from Wikipedia, showing some (slightly dubious) estimates of the number of speakers of each of about 30 languages.  We can read the data in like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>378200000</td>\n",
       "      <td>3</td>\n",
       "      <td>743500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1121000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "      <td>1</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>260000000</td>\n",
       "      <td>4</td>\n",
       "      <td>274200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>534200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "      <td>2</td>\n",
       "      <td>70600000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>512900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>315000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>French</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>76700000</td>\n",
       "      <td>16</td>\n",
       "      <td>208100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>284900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>77000000</td>\n",
       "      <td>15</td>\n",
       "      <td>204000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>281000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>153900000</td>\n",
       "      <td>8</td>\n",
       "      <td>110400000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>264300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>242600000</td>\n",
       "      <td>6</td>\n",
       "      <td>19200000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>261800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>222700000</td>\n",
       "      <td>7</td>\n",
       "      <td>13800000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>236500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Urdu</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>69200000</td>\n",
       "      <td>4</td>\n",
       "      <td>94100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>German</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>76000000</td>\n",
       "      <td>17</td>\n",
       "      <td>56000000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>132000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128200000</td>\n",
       "      <td>9</td>\n",
       "      <td>131000.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>128300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Western Punjabi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>119000000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Iranian</td>\n",
       "      <td>60000000</td>\n",
       "      <td>24</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Swahili</td>\n",
       "      <td>Niger–Congo</td>\n",
       "      <td>Bantu</td>\n",
       "      <td>16000000</td>\n",
       "      <td>28</td>\n",
       "      <td>82300000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>98300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Javanese</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>84300000</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Wu Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>80700000</td>\n",
       "      <td>12</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>80700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>Dravidian</td>\n",
       "      <td>South-Central</td>\n",
       "      <td>74700000</td>\n",
       "      <td>18</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>79700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Turkic</td>\n",
       "      <td>Oghuz</td>\n",
       "      <td>78500000</td>\n",
       "      <td>13</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Koreanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77200000</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>71700000</td>\n",
       "      <td>20</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>74700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Dravidian</td>\n",
       "      <td>South</td>\n",
       "      <td>66600000</td>\n",
       "      <td>22</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>73300000</td>\n",
       "      <td>19</td>\n",
       "      <td>402000.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>73700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>67900000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>64800000</td>\n",
       "      <td>23</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Hausa</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Chadic</td>\n",
       "      <td>43600000</td>\n",
       "      <td>26</td>\n",
       "      <td>19500000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Kra–Dai</td>\n",
       "      <td>Zhuang–Tai</td>\n",
       "      <td>20500000</td>\n",
       "      <td>27</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>60500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Southern Min</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>49700000</td>\n",
       "      <td>25</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                Language         Family             Branch  \\\n",
       "0      1                 English  Indo-European           Germanic   \n",
       "1      2        Mandarin Chinese   Sino-Tibetan            Sinitic   \n",
       "2      3                   Hindi  Indo-European         Indo-Aryan   \n",
       "3      4                 Spanish  Indo-European            Romance   \n",
       "4      5  Modern Standard Arabic   Afro-Asiatic            Semitic   \n",
       "5      6                  French  Indo-European            Romance   \n",
       "6      7                   Malay   Austronesian  Malayo-Polynesian   \n",
       "7      8                 Russian  Indo-European       Balto-Slavic   \n",
       "8      9                 Bengali  Indo-European         Indo-Aryan   \n",
       "9     10              Portuguese  Indo-European            Romance   \n",
       "10    11                    Urdu  Indo-European         Indo-Aryan   \n",
       "11    12                  German  Indo-European           Germanic   \n",
       "12    13                Japanese        Japonic                NaN   \n",
       "13    14         Western Punjabi  Indo-European         Indo-Aryan   \n",
       "14    15                 Persian  Indo-European            Iranian   \n",
       "15    16                 Swahili    Niger–Congo              Bantu   \n",
       "16    17                Javanese   Austronesian  Malayo-Polynesian   \n",
       "17    18              Wu Chinese   Sino-Tibetan            Sinitic   \n",
       "18    19                  Telugu      Dravidian      South-Central   \n",
       "19    20                 Turkish         Turkic              Oghuz   \n",
       "20    21                  Korean       Koreanic                NaN   \n",
       "21    22                 Marathi  Indo-European         Indo-Aryan   \n",
       "22    23                   Tamil      Dravidian              South   \n",
       "23    24             Yue Chinese   Sino-Tibetan            Sinitic   \n",
       "24    25              Vietnamese  Austroasiatic             Vietic   \n",
       "25    26                 Italian  Indo-European            Romance   \n",
       "26    27                   Hausa   Afro-Asiatic             Chadic   \n",
       "27    28                    Thai        Kra–Dai         Zhuang–Tai   \n",
       "28    29            Southern Min   Sino-Tibetan            Sinitic   \n",
       "\n",
       "    L1 speakers  L1 Rank  L2 speakers  L2 Rank       Total  \n",
       "0     378200000        3  743500000.0      1.0  1121000000  \n",
       "1     908700000        1  198400000.0      5.0  1107000000  \n",
       "2     260000000        4  274200000.0      2.0   534200000  \n",
       "3     442300000        2   70600000.0      9.0   512900000  \n",
       "4             0        5  315000000.0      6.0   315000000  \n",
       "5      76700000       16  208100000.0      3.0   284900000  \n",
       "6      77000000       15  204000000.0      4.0   281000000  \n",
       "7     153900000        8  110400000.0      7.0   264300000  \n",
       "8     242600000        6   19200000.0     14.0   261800000  \n",
       "9     222700000        7   13800000.0     15.0   236500000  \n",
       "10     69200000        4   94100000.0      2.0   163200000  \n",
       "11     76000000       17   56000000.0     10.0   132000000  \n",
       "12    128200000        9     131000.0     23.0   128300000  \n",
       "13    119000000       10          NaN      NaN   119000000  \n",
       "14     60000000       24   50000000.0     11.0   110000000  \n",
       "15     16000000       28   82300000.0      8.0    98300000  \n",
       "16     84300000       11          NaN      NaN    84300000  \n",
       "17     80700000       12      63000.0     24.0    80700000  \n",
       "18     74700000       18    5000000.0     17.0    79700000  \n",
       "19     78500000       13     380000.0     22.0    78900000  \n",
       "20     77200000       14          NaN      NaN    77200000  \n",
       "21     71700000       20    3000000.0     18.0    74700000  \n",
       "22     66600000       22    8000000.0     16.0    74600000  \n",
       "23     73300000       19     402000.0     20.0    73700000  \n",
       "24     67900000       21          NaN      NaN    67900000  \n",
       "25     64800000       23    3000000.0     19.0    67800000  \n",
       "26     43600000       26   19500000.0     13.0    63100000  \n",
       "27     20500000       27   40000000.0     12.0    60500000  \n",
       "28     49700000       25     387000.0     21.0    50100000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = pandas.read_csv(\"language_speakers.csv\")\n",
    "langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa!  That's kind of long.  We can use the `.head()` method to look at only the first few rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>378200000</td>\n",
       "      <td>3</td>\n",
       "      <td>743500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1121000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "      <td>1</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>260000000</td>\n",
       "      <td>4</td>\n",
       "      <td>274200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>534200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "      <td>2</td>\n",
       "      <td>70600000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>512900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>315000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                Language         Family      Branch  L1 speakers  \\\n",
       "0     1                 English  Indo-European    Germanic    378200000   \n",
       "1     2        Mandarin Chinese   Sino-Tibetan     Sinitic    908700000   \n",
       "2     3                   Hindi  Indo-European  Indo-Aryan    260000000   \n",
       "3     4                 Spanish  Indo-European     Romance    442300000   \n",
       "4     5  Modern Standard Arabic   Afro-Asiatic     Semitic            0   \n",
       "\n",
       "   L1 Rank  L2 speakers  L2 Rank       Total  \n",
       "0        3  743500000.0      1.0  1121000000  \n",
       "1        1  198400000.0      5.0  1107000000  \n",
       "2        4  274200000.0      2.0   534200000  \n",
       "3        2   70600000.0      9.0   512900000  \n",
       "4        5  315000000.0      6.0   315000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit more manageable.  By default it shows us the first 5 rows, but we can do `.head(10)` to see the first 10 rows, `.head(20)` to see 20, etc.\n",
    "\n",
    "Notice that column of numbers on the far left.  That's the index again.  We can use `.loc` on the index just like we could for a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                       3\n",
       "Language               Hindi\n",
       "Family         Indo-European\n",
       "Branch            Indo-Aryan\n",
       "L1 speakers        260000000\n",
       "L1 Rank                    4\n",
       "L2 speakers        2.742e+08\n",
       "L2 Rank                    2\n",
       "Total              534200000\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this result is itself a Series; each column of a DataFrame is a Series, and each row is also a Series.\n",
    "\n",
    "We can also use `.iloc` as we did before.  In this case, that will be the same, since the index is just numbers in order starting from zero, which is how `.iloc` measures them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                       3\n",
       "Language               Hindi\n",
       "Family         Indo-European\n",
       "Branch            Indo-Aryan\n",
       "L1 speakers        260000000\n",
       "L1 Rank                    4\n",
       "L2 speakers        2.742e+08\n",
       "L2 Rank                    2\n",
       "Total              534200000\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing about a DataFrame, though, is it's two-dimensional.  That means we can now not only access things along the index, but also along the columns.  We can use row and column indices together, in that order.  For instance, we can get rows 3-6 in columns 2-5 like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>76700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Family   Branch  L1 speakers\n",
       "3  Indo-European  Romance    442300000\n",
       "4   Afro-Asiatic  Semitic            0\n",
       "5  Indo-European  Romance     76700000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.iloc[3:6, 2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to specify a column index without a row index, we can use a plain `:` for the row index, which means \"everything\".  So we can get columns 2-5 like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>378200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>260000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>76700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>77000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>153900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>242600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>222700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>69200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>76000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Japonic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>119000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Iranian</td>\n",
       "      <td>60000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Niger–Congo</td>\n",
       "      <td>Bantu</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>84300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>80700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dravidian</td>\n",
       "      <td>South-Central</td>\n",
       "      <td>74700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Turkic</td>\n",
       "      <td>Oghuz</td>\n",
       "      <td>78500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Koreanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>71700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dravidian</td>\n",
       "      <td>South</td>\n",
       "      <td>66600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>73300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>67900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>64800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Chadic</td>\n",
       "      <td>43600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kra–Dai</td>\n",
       "      <td>Zhuang–Tai</td>\n",
       "      <td>20500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>49700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Family             Branch  L1 speakers\n",
       "0   Indo-European           Germanic    378200000\n",
       "1    Sino-Tibetan            Sinitic    908700000\n",
       "2   Indo-European         Indo-Aryan    260000000\n",
       "3   Indo-European            Romance    442300000\n",
       "4    Afro-Asiatic            Semitic            0\n",
       "5   Indo-European            Romance     76700000\n",
       "6    Austronesian  Malayo-Polynesian     77000000\n",
       "7   Indo-European       Balto-Slavic    153900000\n",
       "8   Indo-European         Indo-Aryan    242600000\n",
       "9   Indo-European            Romance    222700000\n",
       "10  Indo-European         Indo-Aryan     69200000\n",
       "11  Indo-European           Germanic     76000000\n",
       "12        Japonic                NaN    128200000\n",
       "13  Indo-European         Indo-Aryan    119000000\n",
       "14  Indo-European            Iranian     60000000\n",
       "15    Niger–Congo              Bantu     16000000\n",
       "16   Austronesian  Malayo-Polynesian     84300000\n",
       "17   Sino-Tibetan            Sinitic     80700000\n",
       "18      Dravidian      South-Central     74700000\n",
       "19         Turkic              Oghuz     78500000\n",
       "20       Koreanic                NaN     77200000\n",
       "21  Indo-European         Indo-Aryan     71700000\n",
       "22      Dravidian              South     66600000\n",
       "23   Sino-Tibetan            Sinitic     73300000\n",
       "24  Austroasiatic             Vietic     67900000\n",
       "25  Indo-European            Romance     64800000\n",
       "26   Afro-Asiatic             Chadic     43600000\n",
       "27        Kra–Dai         Zhuang–Tai     20500000\n",
       "28   Sino-Tibetan            Sinitic     49700000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.iloc[:, 2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy shortcut is that columns can be accessed by using `[]` indexing directly on the DataFrame, without any `.loc` or `.iloc`.  So if we just want the Language column we can do this (I'll use `.head()` again to shorten it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   English\n",
       "1          Mandarin Chinese\n",
       "2                     Hindi\n",
       "3                   Spanish\n",
       "4    Modern Standard Arabic\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs['Language'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get multiple columns this way, by putting in a list of the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Language         Family      Branch\n",
       "0                 English  Indo-European    Germanic\n",
       "1        Mandarin Chinese   Sino-Tibetan     Sinitic\n",
       "2                   Hindi  Indo-European  Indo-Aryan\n",
       "3                 Spanish  Indo-European     Romance\n",
       "4  Modern Standard Arabic   Afro-Asiatic     Semitic"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs[[\"Language\", \"Family\", \"Branch\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want one column, there is an even handier shortcut, which is to just access the column name as an attribute, with a dot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   English\n",
       "1          Mandarin Chinese\n",
       "2                     Hindi\n",
       "3                   Spanish\n",
       "4    Modern Standard Arabic\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, that only works if the name works as a Python attribute (meaning no spaces, symbols, or any of that).  So it's good to know both ways.\n",
    "\n",
    "Another hugely useful way to slice into these tables is to use conditional indexing.  Suppose we want all the languages whose family is Sino-Tibetan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "      <td>1</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Wu Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>80700000</td>\n",
       "      <td>12</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>80700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>73300000</td>\n",
       "      <td>19</td>\n",
       "      <td>402000.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>73700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Southern Min</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>49700000</td>\n",
       "      <td>25</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank          Language        Family   Branch  L1 speakers  L1 Rank  \\\n",
       "1      2  Mandarin Chinese  Sino-Tibetan  Sinitic    908700000        1   \n",
       "17    18        Wu Chinese  Sino-Tibetan  Sinitic     80700000       12   \n",
       "23    24       Yue Chinese  Sino-Tibetan  Sinitic     73300000       19   \n",
       "28    29      Southern Min  Sino-Tibetan  Sinitic     49700000       25   \n",
       "\n",
       "    L2 speakers  L2 Rank       Total  \n",
       "1   198400000.0      5.0  1107000000  \n",
       "17      63000.0     24.0    80700000  \n",
       "23     402000.0     20.0    73700000  \n",
       "28     387000.0     21.0    50100000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs[langs.Family==\"Sino-Tibetan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or suppose we want all Indo-European languages in the top ten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>378200000</td>\n",
       "      <td>3</td>\n",
       "      <td>743500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1121000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>260000000</td>\n",
       "      <td>4</td>\n",
       "      <td>274200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>534200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "      <td>2</td>\n",
       "      <td>70600000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>512900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>French</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>76700000</td>\n",
       "      <td>16</td>\n",
       "      <td>208100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>284900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>153900000</td>\n",
       "      <td>8</td>\n",
       "      <td>110400000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>264300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>242600000</td>\n",
       "      <td>6</td>\n",
       "      <td>19200000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>261800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>222700000</td>\n",
       "      <td>7</td>\n",
       "      <td>13800000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>236500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank    Language         Family        Branch  L1 speakers  L1 Rank  \\\n",
       "0     1     English  Indo-European      Germanic    378200000        3   \n",
       "2     3       Hindi  Indo-European    Indo-Aryan    260000000        4   \n",
       "3     4     Spanish  Indo-European       Romance    442300000        2   \n",
       "5     6      French  Indo-European       Romance     76700000       16   \n",
       "7     8     Russian  Indo-European  Balto-Slavic    153900000        8   \n",
       "8     9     Bengali  Indo-European    Indo-Aryan    242600000        6   \n",
       "9    10  Portuguese  Indo-European       Romance    222700000        7   \n",
       "\n",
       "   L2 speakers  L2 Rank       Total  \n",
       "0  743500000.0      1.0  1121000000  \n",
       "2  274200000.0      2.0   534200000  \n",
       "3   70600000.0      9.0   512900000  \n",
       "5  208100000.0      3.0   284900000  \n",
       "7  110400000.0      7.0   264300000  \n",
       "8   19200000.0     14.0   261800000  \n",
       "9   13800000.0     15.0   236500000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs[(langs.Family=='Indo-European') & (langs.Rank<=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that you *must* use parentheses to separate the conditions there, for somewhat annoying reasons we won't get into.  If you try it without, you'll get an error.)\n",
    "\n",
    "These pandas objects have many useful methods.  We can use the `.describe()` method on a DataFrame to get a summary of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.408276e+08</td>\n",
       "      <td>14.137931</td>\n",
       "      <td>1.007785e+08</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>2.276759e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.514693</td>\n",
       "      <td>1.798507e+08</td>\n",
       "      <td>8.309737</td>\n",
       "      <td>1.631286e+08</td>\n",
       "      <td>7.233717</td>\n",
       "      <td>2.768115e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.300000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.010000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.660000e+07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.470000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.670000e+07</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.100000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.282000e+08</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.104000e+08</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.643000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.087000e+08</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7.435000e+08</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.121000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rank   L1 speakers    L1 Rank   L2 speakers    L2 Rank  \\\n",
       "count  29.000000  2.900000e+01  29.000000  2.500000e+01  25.000000   \n",
       "mean   15.000000  1.408276e+08  14.137931  1.007785e+08  12.080000   \n",
       "std     8.514693  1.798507e+08   8.309737  1.631286e+08   7.233717   \n",
       "min     1.000000  0.000000e+00   1.000000  6.300000e+04   1.000000   \n",
       "25%     8.000000  6.660000e+07   7.000000  3.000000e+06   6.000000   \n",
       "50%    15.000000  7.670000e+07  14.000000  4.000000e+07  12.000000   \n",
       "75%    22.000000  1.282000e+08  21.000000  1.104000e+08  18.000000   \n",
       "max    29.000000  9.087000e+08  28.000000  7.435000e+08  24.000000   \n",
       "\n",
       "              Total  \n",
       "count  2.900000e+01  \n",
       "mean   2.276759e+08  \n",
       "std    2.768115e+08  \n",
       "min    5.010000e+07  \n",
       "25%    7.470000e+07  \n",
       "50%    1.100000e+08  \n",
       "75%    2.643000e+08  \n",
       "max    1.121000e+09  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That shows us basic statistics about each column, like the mean, standard deviation, quartiles, and so on.  Notice it does this even when it might not make any sense; the \"standard deviation\" of the Rank isn't meaningful, but it shows us anyway.  You can also use `.describe()` on a Series, although I'll spare you an example.\n",
    "\n",
    "We can sort a DataFrame using `.sort_index` like we can with a Series.  If we want to sort by the values, we have to specify which column to sort by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Hausa</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Chadic</td>\n",
       "      <td>43600000</td>\n",
       "      <td>26</td>\n",
       "      <td>19500000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>315000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>67900000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>77000000</td>\n",
       "      <td>15</td>\n",
       "      <td>204000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>281000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Javanese</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Malayo-Polynesian</td>\n",
       "      <td>84300000</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                Language         Family             Branch  \\\n",
       "26    27                   Hausa   Afro-Asiatic             Chadic   \n",
       "4      5  Modern Standard Arabic   Afro-Asiatic            Semitic   \n",
       "24    25              Vietnamese  Austroasiatic             Vietic   \n",
       "6      7                   Malay   Austronesian  Malayo-Polynesian   \n",
       "16    17                Javanese   Austronesian  Malayo-Polynesian   \n",
       "\n",
       "    L1 speakers  L1 Rank  L2 speakers  L2 Rank      Total  \n",
       "26     43600000       26   19500000.0     13.0   63100000  \n",
       "4             0        5  315000000.0      6.0  315000000  \n",
       "24     67900000       21          NaN      NaN   67900000  \n",
       "6      77000000       15  204000000.0      4.0  281000000  \n",
       "16     84300000       11          NaN      NaN   84300000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.sort_values('Family').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it sorted the Family column in alphabetical order.  If we want to sort in reverse order we can do that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Turkic</td>\n",
       "      <td>Oghuz</td>\n",
       "      <td>78500000</td>\n",
       "      <td>13</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Southern Min</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>49700000</td>\n",
       "      <td>25</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>73300000</td>\n",
       "      <td>19</td>\n",
       "      <td>402000.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>73700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Wu Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>80700000</td>\n",
       "      <td>12</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>80700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "      <td>1</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank          Language        Family   Branch  L1 speakers  L1 Rank  \\\n",
       "19    20           Turkish        Turkic    Oghuz     78500000       13   \n",
       "28    29      Southern Min  Sino-Tibetan  Sinitic     49700000       25   \n",
       "23    24       Yue Chinese  Sino-Tibetan  Sinitic     73300000       19   \n",
       "17    18        Wu Chinese  Sino-Tibetan  Sinitic     80700000       12   \n",
       "1      2  Mandarin Chinese  Sino-Tibetan  Sinitic    908700000        1   \n",
       "\n",
       "    L2 speakers  L2 Rank       Total  \n",
       "19     380000.0     22.0    78900000  \n",
       "28     387000.0     21.0    50100000  \n",
       "23     402000.0     20.0    73700000  \n",
       "17      63000.0     24.0    80700000  \n",
       "1   198400000.0      5.0  1107000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.sort_values('Family', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful things about Pandas is that you can do operations on whole columns as if they were single values.  The operation just gets applied to every value in the column.  So suppose we want to find the number of first-language speakers minus the number of second-language speakers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -365300000.0\n",
       "1     710300000.0\n",
       "2     -14200000.0\n",
       "3     371700000.0\n",
       "4    -315000000.0\n",
       "5    -131400000.0\n",
       "6    -127000000.0\n",
       "7      43500000.0\n",
       "8     223400000.0\n",
       "9     208900000.0\n",
       "10    -24900000.0\n",
       "11     20000000.0\n",
       "12    128069000.0\n",
       "13            NaN\n",
       "14     10000000.0\n",
       "15    -66300000.0\n",
       "16            NaN\n",
       "17     80637000.0\n",
       "18     69700000.0\n",
       "19     78120000.0\n",
       "20            NaN\n",
       "21     68700000.0\n",
       "22     58600000.0\n",
       "23     72898000.0\n",
       "24            NaN\n",
       "25     61800000.0\n",
       "26     24100000.0\n",
       "27    -19500000.0\n",
       "28     49313000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs['L1 speakers'] - langs['L2 speakers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do such operations on strings.  So suppose we want to smush the Family and Branch together into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Indo-European/Germanic\n",
       "1               Sino-Tibetan/Sinitic\n",
       "2           Indo-European/Indo-Aryan\n",
       "3              Indo-European/Romance\n",
       "4               Afro-Asiatic/Semitic\n",
       "5              Indo-European/Romance\n",
       "6     Austronesian/Malayo-Polynesian\n",
       "7         Indo-European/Balto-Slavic\n",
       "8           Indo-European/Indo-Aryan\n",
       "9              Indo-European/Romance\n",
       "10          Indo-European/Indo-Aryan\n",
       "11            Indo-European/Germanic\n",
       "12                               NaN\n",
       "13          Indo-European/Indo-Aryan\n",
       "14             Indo-European/Iranian\n",
       "15                 Niger–Congo/Bantu\n",
       "16    Austronesian/Malayo-Polynesian\n",
       "17              Sino-Tibetan/Sinitic\n",
       "18           Dravidian/South-Central\n",
       "19                      Turkic/Oghuz\n",
       "20                               NaN\n",
       "21          Indo-European/Indo-Aryan\n",
       "22                   Dravidian/South\n",
       "23              Sino-Tibetan/Sinitic\n",
       "24              Austroasiatic/Vietic\n",
       "25             Indo-European/Romance\n",
       "26               Afro-Asiatic/Chadic\n",
       "27                Kra–Dai/Zhuang–Tai\n",
       "28              Sino-Tibetan/Sinitic\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Family + \"/\" + langs.Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we got NaN in some cases.  `NaN` is just a value that pandas uses to mean \"this value is missing\".  If you do any operation on `NaN` (like adding something to it) you get `NaN` again.\n",
    "\n",
    "We can add a new column to our DataFrame by using syntax similar to that for accessing an existing column.  Suppose we want to make a new column \"FamilyBranch\" that combines Family and Branch as shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "      <th>FamilyBranch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>378200000</td>\n",
       "      <td>3</td>\n",
       "      <td>743500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1121000000</td>\n",
       "      <td>Indo-European/Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "      <td>908700000</td>\n",
       "      <td>1</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107000000</td>\n",
       "      <td>Sino-Tibetan/Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "      <td>260000000</td>\n",
       "      <td>4</td>\n",
       "      <td>274200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>534200000</td>\n",
       "      <td>Indo-European/Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "      <td>442300000</td>\n",
       "      <td>2</td>\n",
       "      <td>70600000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>512900000</td>\n",
       "      <td>Indo-European/Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>315000000</td>\n",
       "      <td>Afro-Asiatic/Semitic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                Language         Family      Branch  L1 speakers  \\\n",
       "0     1                 English  Indo-European    Germanic    378200000   \n",
       "1     2        Mandarin Chinese   Sino-Tibetan     Sinitic    908700000   \n",
       "2     3                   Hindi  Indo-European  Indo-Aryan    260000000   \n",
       "3     4                 Spanish  Indo-European     Romance    442300000   \n",
       "4     5  Modern Standard Arabic   Afro-Asiatic     Semitic            0   \n",
       "\n",
       "   L1 Rank  L2 speakers  L2 Rank       Total              FamilyBranch  \n",
       "0        3  743500000.0      1.0  1121000000    Indo-European/Germanic  \n",
       "1        1  198400000.0      5.0  1107000000      Sino-Tibetan/Sinitic  \n",
       "2        4  274200000.0      2.0   534200000  Indo-European/Indo-Aryan  \n",
       "3        2   70600000.0      9.0   512900000     Indo-European/Romance  \n",
       "4        5  315000000.0      6.0   315000000      Afro-Asiatic/Semitic  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs['FamilyBranch'] = langs.Family + \"/\" + langs.Branch\n",
    "langs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All well and good.  But the real power of pandas comes when you start to use its grouping and aggregating abilities, which allow it to function sort of like a spreadsheet on steroids.\n",
    "\n",
    "Suppose we want to know how many languages in our table fall into each of the various families.  We can use `.groupby` to group on the Family column, then use the `size` method to get the size of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "Afro-Asiatic      2\n",
       "Austroasiatic     1\n",
       "Austronesian      2\n",
       "Dravidian         2\n",
       "Indo-European    13\n",
       "Japonic           1\n",
       "Koreanic          1\n",
       "Kra–Dai           1\n",
       "Niger–Congo       1\n",
       "Sino-Tibetan      4\n",
       "Turkic            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Family').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `groupby` creates a group for each value, and then calling methods on that grouped object calculates something for each group.  In this case, we calculated the size, but we can also calculate something that depends on the other columns, for instance, the total population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "Afro-Asiatic      378100000\n",
       "Austroasiatic      67900000\n",
       "Austronesian      365300000\n",
       "Dravidian         154300000\n",
       "Indo-European    3882300000\n",
       "Japonic           128300000\n",
       "Koreanic           77200000\n",
       "Kra–Dai            60500000\n",
       "Niger–Congo        98300000\n",
       "Sino-Tibetan     1311500000\n",
       "Turkic             78900000\n",
       "Name: Total, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Family').Total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means \"group by `Family`, then for each `Family`, take the `Total` column and `sum` it\".\n",
    "\n",
    "We could also use the `[]` notation if we needed to access a column that has a space in its name or something:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "Afro-Asiatic       43600000\n",
       "Austroasiatic      67900000\n",
       "Austronesian      161300000\n",
       "Dravidian         141300000\n",
       "Indo-European    2237100000\n",
       "Japonic           128200000\n",
       "Koreanic           77200000\n",
       "Kra–Dai            20500000\n",
       "Niger–Congo        16000000\n",
       "Sino-Tibetan     1112400000\n",
       "Turkic             78500000\n",
       "Name: L1 speakers, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Family')['L1 speakers'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the result of each of these is a Series.  We could store that value in a variable and use it later if we wanted to look up these population values for some other purpose, using the methods we discussed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154300000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_pops = langs.groupby('Family').Total.sum()\n",
    "# later\n",
    "family_pops.loc['Dravidian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even apply our own custom functions to each group.  Suppose we want to categorize families as \"big\" (having more than a billion speakers according to this data), or \"small\" (having less than a billion speakers).  We can write a function to do that.  Our function will accept one argument, which will be a DataFrame containing the rows in a particular group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_it_big(tbl):\n",
    "    if tbl.Total.sum() >= 1000000000:\n",
    "        return \"big\"\n",
    "    else:\n",
    "        return \"small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `.apply` on the groupby to apply our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "Afro-Asiatic     small\n",
       "Austroasiatic    small\n",
       "Austronesian     small\n",
       "Dravidian        small\n",
       "Indo-European      big\n",
       "Japonic          small\n",
       "Koreanic         small\n",
       "Kra–Dai          small\n",
       "Niger–Congo      small\n",
       "Sino-Tibetan       big\n",
       "Turkic           small\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Family').apply(is_it_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group on more than one column.  Suppose we want to group by Family and Branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family         Branch           \n",
       "Afro-Asiatic   Chadic                 63100000\n",
       "               Semitic               315000000\n",
       "Austroasiatic  Vietic                 67900000\n",
       "Austronesian   Malayo-Polynesian     365300000\n",
       "Dravidian      South                  74600000\n",
       "               South-Central          79700000\n",
       "Indo-European  Balto-Slavic          264300000\n",
       "               Germanic             1253000000\n",
       "               Indo-Aryan           1152900000\n",
       "               Iranian               110000000\n",
       "               Romance              1102100000\n",
       "Kra–Dai        Zhuang–Tai             60500000\n",
       "Niger–Congo    Bantu                  98300000\n",
       "Sino-Tibetan   Sinitic              1311500000\n",
       "Turkic         Oghuz                  78900000\n",
       "Name: Total, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby(['Family', 'Branch']).Total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our result is still a series, but now the index (those labels on the left) consists of multiple columns.  This is called a MultiIndex.  We can use `.loc` to access its values similar to how we did with one value, but just putting more than one value into the brackets.  Let's stash our family-branch totals in a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_pops = langs.groupby(['Family', 'Branch']).Total.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get individual values out using `.loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63100000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_pops.loc['Afro-Asiatic', 'Chadic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *just might* be useful to you when doing the task you're about to do.  Hint, hint.\n",
    "\n",
    "One other thing that you'll need to do the task below is the `.sample` method.  This method chooses randomly among the rows of a DataFrame, or (if you call it on a Series) the values of a Series.  Suppose we want to choose one of these languages randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    Telugu\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might not look like it, but that result is a Series.  It happens to be a Series that only has one item, but it gives itself away with that stuff at the bottom about \"Name\" and \"dtype\" that we've seen before.  If we wanted to get the language name itself, as a string, we could use `.iloc` to get the first (and only) value in the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yue Chinese'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.sample().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably got a different value that time than you did in the first `sample` call, because every time we call `sample`, it makes a new random choice.\n",
    "\n",
    "When we use `.iloc` we just get the value.  Sometimes we might want the index (or \"name\") instead.  For instance, suppose we grab a random value from our `fb_pops` Series above.  I'll store it in a variable so it won't keep changing as we do a few things with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family         Branch \n",
       "Indo-European  Romance    1102100000\n",
       "Name: Total, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pop = fb_pops.sample()\n",
    "random_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `.iloc` we just get the number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79700000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_pops.sample().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice, but sort of meaningless without knowing what language it refers to.  We can get that using the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Afro-Asiatic', 'Chadic')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_pops.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.index` attribute gives us access to the index of a Series or DataFrame.  Since this is a MultiIndex, its values are tuples.  The index is somewhat like an extra column of values, except it's a little weird in certain ways we won't get into right now.  Suffice it to say that if you have stuff in the index that you want to get at, you can get it in the way we just showed.  Hint, hint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample` gave us a one-item Series because by default it returns just one value.  We could choose a different number if we want, by passing our desired sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26               Hausa\n",
       "1     Mandarin Chinese\n",
       "13     Western Punjabi\n",
       "23         Yue Chinese\n",
       "25             Italian\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `sample` samples \"without replacement\", which is like drawing from a deck of cards: if we had a deck with one card for each language, and we drew Telugu from the deck, then we've removed it, and we can't draw it again because it's not in the deck anymore.  (We could draw it again if we reshuffle the whole deck, which is like making new, separate call to `sample`.)\n",
    "\n",
    "If we want, we can sample \"with replacement\", which is more like rolling a die or spinning a spinner.  Suppose we had a spinner with one wedge for each language, and we spun it.  If we spin Telugu, there's nothing stopping us from spinning again and getting Telugu again.  To do that, we just tell `sample` to do replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3         Spanish\n",
       "16       Javanese\n",
       "23    Yue Chinese\n",
       "2           Hindi\n",
       "19        Turkish\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.sample(5, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run that cell a few times, you should see some cases where the same language appears more than once, verifying that replacement is indeed happening.\n",
    "\n",
    "There's one more nifty feature of `sample`, which is that we can pass it a list of \"weights\".  If we do, it will choose among the values, not equally, but according to the weights, so that values with higher weights are chosen more often.  For instance, suppose we want to choose a language, but with a weighted choice, where we're more likely to choose a languages that have more speakers.  We can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              English\n",
       "2                Hindi\n",
       "1     Mandarin Chinese\n",
       "0              English\n",
       "11              German\n",
       "19             Turkish\n",
       "12            Japanese\n",
       "0              English\n",
       "0              English\n",
       "1     Mandarin Chinese\n",
       "Name: Language, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.Language.sample(10, replace=True, weights=langs.Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run that a few times, you should find that you get a higher than average amount English and Mandarin and Hindi and Spanish and somewhat less of Thai and Italian and so on.  It's sort of like choosing a *person* at random from the world and asking what language they speak; if you were able to choose a random person from the world, you'd be more likely to get one who speaks Mandarin than Italian, because there are just a lot more people who speak Mandarin than Italian.\n",
    "\n",
    "(It's important to note, though, that this is only *sort of* like choosing a person at random, for at least two important reasons: First, although the languages in this table cover a large part of the world's population, they don't cover it all; there are millions of people who speak, for instance, Zulu, but you won't get them with our process because they're not in our table.  It's important to remember that in computational linguistics we're always limited by the data we're using.  Second, of course, many people in the world speak more than one language.  This means that if we choose a random person, they might speak more than one language, and it also means that the population totals in our table probably overlap: there are a considerable number of people who speak both English and Spanish, for example.  And that's leaving aside the issue of whether this table is accurate or not, which, as noted in [the Wikipedia article where it came from](https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers), it probably isn't.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "\n",
    "Now your turn.  Here are a couple simple warm-up tasks to practice working with pandas.  We'll keep using the `langs` DataFrame from above.\n",
    "\n",
    "Select the rows that have Afro-Asiatic languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Family</th>\n",
       "      <th>Branch</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L1 Rank</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>L2 Rank</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Semitic</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>315000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Hausa</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>Chadic</td>\n",
       "      <td>43600000</td>\n",
       "      <td>26</td>\n",
       "      <td>19500000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                Language        Family   Branch  L1 speakers  L1 Rank  \\\n",
       "4      5  Modern Standard Arabic  Afro-Asiatic  Semitic            0        5   \n",
       "26    27                   Hausa  Afro-Asiatic   Chadic     43600000       26   \n",
       "\n",
       "    L2 speakers  L2 Rank      Total  \n",
       "4   315000000.0      6.0  315000000  \n",
       "26   19500000.0     13.0   63100000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs[langs.Family == 'Afro-Asiatic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the \"Language\", \"L1 speakers\", \"L2 speakers\", and \"Total\" columns of the languages that have between 100 million and 500 million L2 speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>L1 speakers</th>\n",
       "      <th>L2 speakers</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>908700000</td>\n",
       "      <td>198400000.0</td>\n",
       "      <td>1107000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>260000000</td>\n",
       "      <td>274200000.0</td>\n",
       "      <td>534200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modern Standard Arabic</td>\n",
       "      <td>0</td>\n",
       "      <td>315000000.0</td>\n",
       "      <td>315000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>French</td>\n",
       "      <td>76700000</td>\n",
       "      <td>208100000.0</td>\n",
       "      <td>284900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malay</td>\n",
       "      <td>77000000</td>\n",
       "      <td>204000000.0</td>\n",
       "      <td>281000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>153900000</td>\n",
       "      <td>110400000.0</td>\n",
       "      <td>264300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Language  L1 speakers  L2 speakers       Total\n",
       "1        Mandarin Chinese    908700000  198400000.0  1107000000\n",
       "2                   Hindi    260000000  274200000.0   534200000\n",
       "4  Modern Standard Arabic            0  315000000.0   315000000\n",
       "5                  French     76700000  208100000.0   284900000\n",
       "6                   Malay     77000000  204000000.0   281000000\n",
       "7                 Russian    153900000  110400000.0   264300000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Language', 'L1 speakers', 'L2 speakers', 'Total']\n",
    "langs[columns][(langs['L2 speakers'] >= 100000000) & (langs['L2 speakers'] <= 500000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of languages in each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Branch\n",
       "Balto-Slavic         1\n",
       "Bantu                1\n",
       "Chadic               1\n",
       "Germanic             2\n",
       "Indo-Aryan           5\n",
       "Iranian              1\n",
       "Malayo-Polynesian    2\n",
       "Oghuz                1\n",
       "Romance              4\n",
       "Semitic              1\n",
       "Sinitic              4\n",
       "South                1\n",
       "South-Central        1\n",
       "Vietic               1\n",
       "Zhuang–Tai           1\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Branch').count()['Language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the total L2 speakers of each family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "Afro-Asiatic     3.345000e+08\n",
       "Austroasiatic    0.000000e+00\n",
       "Austronesian     2.040000e+08\n",
       "Dravidian        1.300000e+07\n",
       "Indo-European    1.645900e+09\n",
       "Japonic          1.310000e+05\n",
       "Koreanic         0.000000e+00\n",
       "Kra–Dai          4.000000e+07\n",
       "Niger–Congo      8.230000e+07\n",
       "Sino-Tibetan     1.992520e+08\n",
       "Turkic           3.800000e+05\n",
       "Name: L2 speakers, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Family').sum()['L2 speakers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column called \"Length\" to the table, containing the length of the name of each language (so \"English\" will be 7 because it has seven letters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7\n",
       "1     15\n",
       "2      5\n",
       "3      7\n",
       "4     20\n",
       "5      6\n",
       "6      5\n",
       "7      7\n",
       "8      7\n",
       "9     10\n",
       "10     4\n",
       "11     6\n",
       "12     8\n",
       "13    14\n",
       "14     7\n",
       "15     7\n",
       "16     8\n",
       "17     9\n",
       "18     6\n",
       "19     7\n",
       "20     6\n",
       "21     7\n",
       "22     5\n",
       "23    10\n",
       "24    10\n",
       "25     7\n",
       "26     5\n",
       "27     4\n",
       "28    11\n",
       "Name: Length, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_charCount = langs.Language.apply(lambda x: len(x.replace(' ', '')))\n",
    "\n",
    "langs['Length'] = lang_charCount\n",
    "langs['Length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average number of speakers of languages with each name length.  (That is, your result should have a row whose index is 7, and the value in that row shoud be the average number of speakers in languages with seven letters in their name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Length\n",
       "4     1.118500e+08\n",
       "5     2.382250e+08\n",
       "6     1.434500e+08\n",
       "7     2.877444e+08\n",
       "8     1.063000e+08\n",
       "9     8.070000e+07\n",
       "10    1.260333e+08\n",
       "11    5.010000e+07\n",
       "14    1.190000e+08\n",
       "15    1.107000e+09\n",
       "20    3.150000e+08\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.groupby('Length').mean()['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the table by Family *and* Length and find the size of each group.  Store your result in a variable.  (Don't forget to display it too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family         Length\n",
       "Afro-Asiatic   5           63100000\n",
       "               20         315000000\n",
       "Austroasiatic  10          67900000\n",
       "Austronesian   5          281000000\n",
       "               8           84300000\n",
       "Dravidian      5           74600000\n",
       "               6           79700000\n",
       "Indo-European  4          163200000\n",
       "               5          534200000\n",
       "               6          416900000\n",
       "               7         2412500000\n",
       "               10         236500000\n",
       "               14         119000000\n",
       "Japonic        8          128300000\n",
       "Koreanic       6           77200000\n",
       "Kra–Dai        4           60500000\n",
       "Niger–Congo    7           98300000\n",
       "Sino-Tibetan   9           80700000\n",
       "               10          73700000\n",
       "               11          50100000\n",
       "               15        1107000000\n",
       "Turkic         7           78900000\n",
       "Name: Total, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_size = langs.groupby(['Family', 'Length']).sum()['Total']\n",
    "\n",
    "group_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the variable you just created, get the value correponding to Indo-European languages with 7 letters in their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2412500000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_size['Indo-European'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's a brief introduction to the capabilities of pandas.  We're only scratching the surface of what's possible here.  Half the time when you think of something you want to do, it'll turn out there's a simple shortcut for it with pandas.  But what we've just done is enough for us to build a simple text-generation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chains\n",
    "\n",
    "Last week in the \"Bil dams\" exercise you finished up by creating a list of n-grams in this format:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"Size\": 1, \"Gram\": ('A',), \"Word\": \"house\"},\n",
    "    {\"Size\": 1, \"Gram\": ('house',), \"Word\": \"is\"},\n",
    "    {\"Size\": 1, \"Gram\": ('is',), \"Word\": \"a\"},\n",
    "]\n",
    "```\n",
    "\n",
    "(At least I hope you did, because that's going to be our starting point today.)\n",
    "\n",
    "Today we'll do something similar using a more interesting dataset: a collection of quotes.  The file `quotes.csv` contains our data in CSV format.  Unlike before, it is not just one long string, but is in tabular format.\n",
    "\n",
    "Note: Some of the results in this assignment will be long.  Use `.head()` if necessary when displaying your result at the end to show only the first few rows, or use something like `[:5]` to show only the first few items of a list.\n",
    "\n",
    "Note 2: You must do this assignment using `pandas`.  Part of the assignment is learning to use pandas.  You will not receive credit if you turn in a Markov chain generator that is not built with pandas data structures, even if it is functional.\n",
    "\n",
    "**Exercises:**\n",
    "\n",
    "First, read in the file using `pandas.read_csv` and store it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quotes = pd.read_csv('quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are three columns: `Quote` contains the quote. `Author` contains the author.  `Topic` contains some label for what the quote is about.\n",
    "\n",
    "There are a lot of quotes in this dataset (more than 75,000).  Let's restrict ourselves to just the quotes about hope.  Make a new variable containing only the rows from our DataFrame whose `Topic` is `\"hope\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope = quotes[quotes.Topic == 'hope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now work basically with only the `Quote` column of this table, since we don't need the author.\n",
    "\n",
    "Working with that column, build up a list of dictionaries in the format you did for Bil Dams (as shown above).  It should include ngram sizes from 1 up to 4 (so `Size` will range from 0 to 3).  (Remember that `Size` is the size of the `Gram`, which is one less than the ngram size we're using, because we're chopping off the last word and separating it as `Word` in our dict.)  You can re-use your code from before, but you will have to modify it slightly, perhaps running it in a loop, because our data now consists of many small \"documents\" (the individual quotes) instead of one big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-09e3bd7a8244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "gram_list = []\n",
    "\n",
    "for quote in hope:\n",
    "    \n",
    "    tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "    toks = tokenizer.tokenize(quote)\n",
    "    \n",
    "    for word1, word2 in nltk.ngrams(toks, bigram_number):\n",
    "        dic_item = {\"Size\": bigram_number-1, \"Gram\": (word1,), \"Word\": word2}\n",
    "        \n",
    "    # Unigram\n",
    "    for word in nltk.ngrams(toks, unigram_number):\n",
    "        dic_item = {\"Size\": unigram_number-1, \"Gram\": (), \"Word\": word[0]}\n",
    "        gram_list.append(dic_item)\n",
    "\n",
    "    # Bigram\n",
    "    for word1, word2 in nltk.ngrams(toks, bigram_number):\n",
    "        dic_item = {\"Size\": bigram_number-1, \"Gram\": (word1,), \"Word\": word2}\n",
    "        gram_list.append(dic_item)\n",
    "\n",
    "    # Trigram \n",
    "    for word1, word2, word3 in nltk.ngrams(toks, trigram_number):\n",
    "        dic_item = {\"Size\": trigram_number-1, \"Gram\": (word1, word2,), \"Word\": word3}\n",
    "        gram_list.append(dic_item)\n",
    "    \n",
    "    # Quadgram \n",
    "    for word1, word2, word3, word4 in nltk.ngrams(toks, quadgram_number):\n",
    "        dic_item = {\"Size\": quadgram_number-1, \"Gram\": (word1, word2, word3), \"Word\": word4}\n",
    "        gram_list.append(dic_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `pandas.DataFrame.from_records` to convert this into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gram_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d663f4c687e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhope_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgram_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gram_list' is not defined"
     ]
    }
   ],
   "source": [
    "hope_gram = pd.DataFrame.from_records(gram_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort your DataFrame in-place by Size, Gram and Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `.groupby` to group this DataFrame by all three columns and find the size of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure we've just created allows us to see all the possibilities for which words could occur in a given context in our source text, and how many times each one occurred.  Use it to find out all the words that could come after the two-word sequence \"hope for\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use it to find all the words that could come after the word \"human\".  (Be careful!  Certain elements in your data structure are tuples, and you will have to use a one-element tuple since we are only looking for one word.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's think about this a minute.  If we do what you did above, we can find all the words that come after \"human\".  Suppose we choose one of them randomly.  Then we could find all the words that come after *that* word, and choose one of *them* randomly.  And then we could find all the words that come after *that* one, and choose one of *them* randomly.  And since we have the frequencies, we won't actually be choosing \"totally randomly\"; instead, we can use `.sample` to weight our choice so that we choose more common follow-up words more frequently.  By continuing this process, we can generate a new text that mimics some aspect of the sequential structure of the original text.\n",
    "\n",
    "We only need two things: One is a starting word (like \"human\" here) to kick-start the process.  The other is some way to know when to stop.  One easy way to do that is to keep going until the \"next word\" that we choose is a period, which will mean we'll generate a full sentence (or some approximation of one).\n",
    "\n",
    "So let's do it.  Write a loop that starts with some \"seed word\" (maybe \"the\"?).  Your loop should use the current word to look up what words might come next, use `.sample` to choose one of them, and repeat the process with that new word as the new seed word.  As you go, build up a list of the words you're choosing, and stop when you get to a period.\n",
    "\n",
    "(Don't worry if the results you get look somewhat peculiar, in the sense of having spaces or punctuation in odd places.  There are various formatting issues that we're not going to worry about here, largely arising from some of the issues we discussed, where things like punctuation get treated as \"words\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try doing the same thing, but instead of using one word to look up the next word, use *two* words to look up the next word.  That is, if we are generating our sentence and so far we have \"in the\", then instead of just using `(\"the\",)` to look up our next word, we'll use `('in', 'the')`.  This means that instead of keeping track of just one \"seed word\", you'll have to keep track of two, and \"rotate\" them so that when you pick a new word, it pushes out one of the two existing seed words and keeps the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that this latter version occasionally throws an error --- but not every time.  That's one aspect of working with randomized processes: they can sometimes fail, and it's hard to know exactly what caused it, because it was due to some particular combination of random choices you made that may be difficult to reproduce.  Ah well.  We'll talk about that in the questions below.  But first, we'll try a slightly more complex version that should be able to get rid of those errors, if we do it right.\n",
    "\n",
    "Before that, though, one final exercise: write a version that implements some version of the \"backoff\" procedure described in [the reading](https://blog.dataiku.com/2016/10/08/machine-learning-markov-chains-generate-clinton-trump-quotes).  That is, your model should use two words to look up the next one, but if there isn't enough variety in the available matches, it should \"back off\" and try using only one word instead.  If there isn't enough variety even then, it should \"back off\" even more and use no words!  You'll have to think about what it means to choose a word using zero words of context, but the data you've created should have what you need to do it.  You can choose the backoff threshold (or \"size requirement\" as it's called in the reading); you may want to experiment with a couple different values.\n",
    "\n",
    "You should try to make this version run without raising errors.  If you do still wind up with errors, be sure to write some commentary explaining your best guess about why the error is happening and what you tried to do to solve it.  (It's still possible that your Markov generator may produce some strange output, in the sense of having punctuation in odd places and the like, but that's fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some plain old questions:\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What possible uses can you think of for Markov chains, other than the ones we already discussed in class?\n",
    "2. Why do the results of this text generator sometimes look \"messy\" or not like real sentences?  What could be done to fix this?  (You don't have to actually do it, just give the general idea of what you think would be required.)\n",
    "3. In those examples we used first one word of \"context\", then two words.  What if we extended it to three, or four, or five words?  Do you think this would make the results \"better\" or \"worse\" (or both!)?  How and why?\n",
    "4. When you expanded the context from one word to two, did you occasionally get errors if you re-ran your code several times?  Why did this happen?  Did your last version (with \"backoff\") fix the problem?  How did it do so?\n",
    "5. In the final exercise, what did it mean to use \"no words\" of context?  How did you pick which word to use next without using any previous words?\n",
    "6. Did you have to look up any documentation, StackOverflow questions, or other outside resources to help you finish this assignment?  If so, give an example of one thing you had to look up, and what you found, and how it helped you.\n",
    "\n",
    "Be sure to submit your notebook file on GauchoSpace for credit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
