{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "\n",
    "## Welcome to the Juptyer notebook!\n",
    "\n",
    "The Jupyter notebook is a widely used tool for creating and sharing interactive documents that combine source code and the output that it generates.  In this class you will be using Jupyter to do your assignments.  (Sometimes people will also talk about \"IPython notebooks\".  Basically IPython was the old name for what is now called Jupyter.)\n",
    "\n",
    "A Jupyter notebook is made of \"cells\".  A cell is a block containing some sort of content.  We will mostly use two types of cells: Code cells and Markdown cells.\n",
    "\n",
    "A Markdown cell is sort of like a mini web page, written in a shorthand format called Markdown.  You can use Markdown cells to provide description and explanation that goes along with your code.  This cell you are reading now is a Markdown cell.  If you double-click it you can see its source code, which as you'll notice is pretty simple.  You can get more info about the details of Markdown from the Help menu at the top of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational linguistics is gonna be so rad!\n"
     ]
    }
   ],
   "source": [
    "# But the real cool part of the Jupyter notebook is the Code cells\n",
    "# A code cell contains Python code you can run, and its output will be displayed below.\n",
    "# Notice that since this is code, I have to type this explanation in comments\n",
    "\n",
    "# You can press Ctrl+Enter to run this cell and see the output displayed below\n",
    "print(\"Computational linguistics is gonna be so rad!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can and should mix Code and Markdown cells within your notebook.  Your Code cells will do the actual work, and your Markdown cells can explain what the code is doing.  (You can also use comments in Code cells, as shown above.)\n",
    "\n",
    "You can put any code you want in a Code cell.  Your notebook has Python running behind the scenes.  So that code you execute in one cell still has its effect for cells you run later.  For instance, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_friends = [\"Al\", \"Bob\", \"Cindy\", \"Duncan\", \"Emilio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there is no output there, because we didn't print anything or otherwise do anything that would produce output.  But if you ran that cell, the variable `my_friends` was created, and you can use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm friends with Al\n",
      "I'm friends with Bob\n",
      "I'm friends with Cindy\n",
      "I'm friends with Duncan\n",
      "I'm friends with Emilio\n"
     ]
    }
   ],
   "source": [
    "for friend in my_friends:\n",
    "    print(\"I'm friends with\", friend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think of it is that all the code in your Code cells is part of one big Python program that you are running a little bit at a time, one piece in each cell.\n",
    "\n",
    "However, it is important to keep in mind that things happen in the order you *run* them, which is not necessarily the order they appear from top to bottom in the notebook.  For instance, suppose you run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_friends = [\"Fred\", \"Gus\", \"Helen\", \"Iris\", \"Jamal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now go back and run the cell with the `for` loop, it will print out all your new friends, because you overwrote the old value of `my_friends` that you set in an earlier cell.\n",
    "\n",
    "This is not necessarily a problem, but it's just something to keep in mind.  If you find you're getting weird results or errors, it may be because you went back and ran cells in some strange order, so that one cell was working with different data than you expected.\n",
    "\n",
    "The notebook also has some nifty help facilities.  Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "range(stop) -> range object\n",
       "range(start, stop[, step]) -> range object\n",
       "\n",
       "Return an object that produces a sequence of integers from start (inclusive)\n",
       "to stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\n",
       "start defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\n",
       "These are exactly the valid indices for a list of 4 elements.\n",
       "When step is given, it specifies the increment (or decrement).\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what that did?  It popped up a little panel at the bottom that shows you the documentation for the `range` function.  This is what the `?` command does, and you should use it often.  You can use it on Python functions, classes, objects, modules, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        module\n",
       "\u001b[1;31mString form:\u001b[0m <module 'collections' from 'C:\\\\FakeProgs\\\\Anaconda3\\\\envs\\\\compling\\\\lib\\\\collections\\\\__init__.py'>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\fakeprogs\\anaconda3\\envs\\compling\\lib\\collections\\__init__.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "This module implements specialized container datatypes providing\n",
       "alternatives to Python's general purpose built-in containers, dict,\n",
       "list, set, and tuple.\n",
       "\n",
       "* namedtuple   factory function for creating tuple subclasses with named fields\n",
       "* deque        list-like container with fast appends and pops on either end\n",
       "* ChainMap     dict-like class for creating a single view of multiple mappings\n",
       "* Counter      dict subclass for counting hashable objects\n",
       "* OrderedDict  dict subclass that remembers the order entries were added\n",
       "* defaultdict  dict subclass that calls a factory function to supply missing values\n",
       "* UserDict     wrapper around dictionary objects for easier dict subclassing\n",
       "* UserList     wrapper around list objects for easier list subclassing\n",
       "* UserString   wrapper around string objects for easier string subclassing\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "?collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get similar help by hitting `Shift+Tab` when your cursor is at the end of the name of a class, module or function.  Try moving your cursor to the end of the line above and hitting `Shift+Tab`.  If you hold `Shift` and hit `Tab` again, the help window will expand somewhat, and if you keep holding `Shift` and hit `Tab` twice more, you'll get the separate panel at the bottom of the screen.  In other words, hold `Shift` and keep hitting `Tab` as long as you need more information!\n",
    "\n",
    "There is another feature of the notebook that you will find useful in exploring new functions and libraries.  If in a code cell you hit the `Tab` key, the notebook will pop up a list of possible \"completions\" of what you have typed so far.  Try putting your cursor at the end of each line below and hitting `Tab` to see what you get.  (Note that if you run this cell, you'll get an error, because the code is incomplete.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col\n",
    "collections.de\n",
    "collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing your homework\n",
    "\n",
    "Your homework assignments will be given as Jupyter notebooks.  In fact, you're doing one right now.\n",
    "\n",
    "Interspersed through all this fascinating commentary and edification, there will be places where you are asked to fill in your own work.  Often this will be in the form of code.  For instance, if I asked you to make a list of the letters in \"UCSB\" and print it, you would do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U', 'C', 'S', 'B']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucsb = list(\"UCSB\")\n",
    "ucsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I evaluated the variable at the end. which causes it to be displayed.  I could also have printed it using `print(ucsb)`.\n",
    "\n",
    "When you're asked to write code, you should generally either evaluate or print the result at the end, so it's easily visible in the notebook.  You can think of this as sort of like \"showing your intermediate steps\" --- rather than having everything in one giant cell, you should show the pieces of your work as it's built up.  If the result of one cell is very long, you may print only part of it to keep things tidy.  (There are some cases where there may be no result to display, for instance if you are just defining a function that will not be used until later.)\n",
    "\n",
    "Some of the assignments will depend on data files that will provided for you on GauchoSpace.  The code in the notebook includes a filename that will generally look like `Data/some_file_name.txt`.  You may need to change these filenames depending on where you put the files when you downloaded them.\n",
    "\n",
    "**Your submitted notebooks should include all output as well as the code.**  The idea is that if someone were to run your notebook themselves, they should get the same results you got (aside from differences due to random choices, etc.), but they shouldn't *have* to run it to see the results you got; they should just be able to look and see the results too.\n",
    "\n",
    "Before you submit your assignment, take a look over your notebook to make sure you did all the tasks and ran everything in the correct order.  If you look at the top menu of the notebook, under \"Kernel\" is an option for \"Restart and run all\", which, as the name suggests, clears everything out and re-runs all the cells from the beginning.  It's usually a good idea to do this once you think you have everything working.  Then you can scan through the notebook and make sure there are no errors or unexpected behaviors.\n",
    "\n",
    "**Exercises:**\n",
    "\n",
    "Here's your first task: make a list whose elements are your first and last name (as strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reverse each string in the list.  (Don't reverse the list itself, reverse the strings.  So if my list was `['Brendan', 'Barnwell']` my new list should be `['nadnerB', 'llewnraB']`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks a bit weird with the capital letter at the end.  Write code that modifiers your list so the capital is at the beginning of each reversed word.  So my new list would be `['Nadnerb', 'Llewnrab']`.  (Hint: you can use some string methods to do this.  Try typing a string in the code cell, typing a period after it, and hitting tab.  Look through the list of methods for something that looks promising.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo!  You're on pace for an A+.\n",
    "\n",
    "There will also be parts where you are asked to write in Markdown cells to answer questions in a more traditional textual format.  You can either type your answer within the same Markdown cell where the question is, or add your own cell after it with your answer.  Be sure not to erase the question, though.  Here goes...\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Why did you decide to take Linguistics 111?  Answer in a sentence or two (or three if you just can't stop yourself).\n",
    "2. How much programming have you done prior to this class, if any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how you'll do your homework.  When you're done going through this whole notebook, you'll upload your notebook file (which has the extension `.ipynb`) to GauchoSpace, just like you would to turn in an \"analog\" assignment like a written paper.\n",
    "\n",
    "## Mad libs\n",
    "\n",
    "The above was just a brief introduction to using the Jupyter notebook.  The code you'll be writing is the same kind of Python code you know and love from Ling 110.  To warm up, we're going to turn to what may be the simplest possible of example of something that might by some stretch of the imagination be called \"computational linguistics\" --- namely, mad libs.\n",
    "\n",
    "In case you missed out during your childhood, mad libs are \"template\" sentences with blanks specifying some category or part of speech.  An unsuspecting victim is asked for words that fit each category, and then these words are used to fill in the blanks, creating something that is usually ridiculous.  For instance, we might have a template like this:\n",
    "\n",
    "> One fine morning, \\_\\_(your name)\\_\\_ was walking down the street when a(n) \\_\\_(scary animal)\\_\\_ jumped out from behind a(n) \\_\\_(plant)\\_\\_.  It was waving its \\_\\_(body part)\\_\\_ and making noises that sounded like a(n) \\_\\_(noise)\\_\\_.  Thinking quickly, \\_\\_(your name)\\_\\_ pulled out a \\_\\_(kitchen utensil)\\_\\_ and began to \\_\\_(physical motion)\\_\\_.  The \\_\\_(scary animal)\\_\\_ \\_\\_(intransitive verb)\\_\\_ed and ran away.\n",
    "\n",
    "Then of course you ask your friend to supply their name, a scary animal, a body part, etc., and you wind up with something like this:\n",
    "\n",
    "> One fine morning, **Brendan** was walking down the street when a **potato bug** jumped out from behind a **daisy**.  It was waving its **appendix** and making noises that sounded like a **toilet flushing**.  Thinking quickly, **Brendan** pulled out a **spatula** and began to **limbo**.  The **potato bug** **snor**ed and ran away.\n",
    "\n",
    "Our mad lib project will be a slight variation on this.  Your task is to create a mad lib template like the above, and then, for each blank, a set of at least five words that could fill it in.  Then you should write a function which, when called should write a cell which, when run, will fill in the blanks with randomly-chosen words from the appropriate sets, and print the resulting completed mad lib.\n",
    "\n",
    "In order to do this you will make use of Python's string templating.  Your template string should look like this:\n",
    "\n",
    "    \"One fine morning {name} was walking down the street when a(n) {scary_animal} jumped out from behind a(n) {plant}.\"\n",
    "    \n",
    "At the critical moment, you will then fill in the blanks by using a Python dictionary passed to the `format` method of this string.  Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One fine morning Brendan was walking down the street when a potato bug jumped out from behind a daisy.\n"
     ]
    }
   ],
   "source": [
    "template = \"One fine morning {name} was walking down the street when {scary_animal} jumped out from behind {plant}.\"\n",
    "blanks = {\n",
    "    \"name\": \"Brendan\",\n",
    "    \"scary_animal\": \"a potato bug\",\n",
    "    \"plant\": \"a daisy\"\n",
    "}\n",
    "\n",
    "print(template.format(**blanks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case I chose to include the article (a/an) with the blank-filling word, since it looks a bit nicer.\n",
    "\n",
    "Yours, of course, will be slightly more complex than this, since you will need multiple words for each blank, and you'll need to choose randomly among them.\n",
    "\n",
    "This exercise, like all assignments in this class, will be done as a notebook.  When doing the assignments, you should use Markdown cells for longer bits of description that in some sense \"narrate\" the overall flow of the task.  You can still use comments within Code cells for more local comments about specific bits of code.\n",
    "\n",
    "**Exercises:**\n",
    "\n",
    "First, import any modules you may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a hint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write a template string with placeholders in curly braces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a dictionary where each key is the name of one of your placeholders, and each value is a list of strings that could fill in that blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to write the \"meat\" of your mad lib code.  You should make a new dictionary whose keys are the same as your placeholder dictionary above, but where each value is a single string chosen randomly from the list in the other dictionary.  You'll need to use a function from the `random` module to do this, which means you may need to browse [the documentation](https://docs.python.org/3/library/random.html).  At the end, call the `.format` method of your template string and pass your dictionary using `**` as demonstrated in the example above.\n",
    "\n",
    "You can do this all in one cell, or you can use a separate cell for each step.  Using separate cells may help you check that each step is working as you intend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bil dams\n",
    "\n",
    "Now we will try \"bil dams\" --- mad libs in reverse.  Imagine that you saw some text like one of our filled-in Mad libs:\n",
    "\n",
    "> One fine morning, Brendan was walking down the street when a potato bug jumped out from behind a daisy.  It was waving its appendix and making noises that sounded like a toilet flushing.  Thinking quickly, Brendan pulled out a spatula and began to limbo.  The potato bug snored and ran away.\n",
    "\n",
    "Suppose we want to somehow reverse-engineer this to put blanks back in that we could fill in with other words.\n",
    "\n",
    "Of course, there's no real way to know where the blanks originally were.  But if we see words that occur frequently in the sentence (or in a longer text), with many different words following just after them, then we could hypothesize that it would be a good idea to put blanks in those spots just after them.  For instance, in the example above, we see the word \"a\" occurs several times, with different words after it:\n",
    "\n",
    "> One fine morning, Brendan was walking down the street when **a&#8203;** *potato* bug jumped out from behind **a&#8203;** *daisy*.  It was waving its appendix and making noises that sounded like **a&#8203;** *toilet* flushing.  Thinking quickly, Brendan pulled out **a&#8203;** *spatula* and began to limbo.  The potato bug snored and ran away.\n",
    "\n",
    "Note that this doesn't totally recreate the blanks as before, for a few reasons.  One reason is that if we look for \"a\", we'll only find, well, \"a\", and not \"an\", even though those two words are basically equivalent in terms of where we might want to put a blank.  Another reason is that if there were multiple words in the blank (as in \"potato bug\" or \"toilet flushing\"), our strategy will only find the first word.\n",
    "\n",
    "Still, it's a start!\n",
    "\n",
    "To do this we will use some functions from the `nltk` library.  This is sort of a \"lite\" version of the `spacy` library that you used in Ling 110.  `spacy` is considerably more powerful overall, but for some simple tasks `nltk` is more convenient.\n",
    "\n",
    "NLTK has several simple tokenizers that will take text and split it up into words (or sentences or the like).  In this class we will mostly use the `TweetTokenizer` as it makes somewhat fewer assumptions.  The tokenizer just takes a string and returns a list of string tokens.\n",
    "\n",
    "The file `simple_house.txt` contains the introductory paragraphs from the Simple English Wikipedia article for \"House\".  It has been \"cleaned up\" by pasting the whole thing into one big string, removing paragraph breaks and the like.  NLTK also provides a simple function to read in the text file as one big string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "doc = nltk.load('Data/simple_house.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is just a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at the beginning of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A house is a building that is '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the tokenizer to convert that text into a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "toks = tokenizer.tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that what we got is a list. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". . . of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(toks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again we can look at the beginning.  Note that now our indexes are by words, not by characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'house',\n",
       " 'is',\n",
       " 'a',\n",
       " 'building',\n",
       " 'that',\n",
       " 'is',\n",
       " 'made',\n",
       " 'for',\n",
       " 'people',\n",
       " 'to',\n",
       " 'live',\n",
       " 'in',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " '\"',\n",
       " 'permanent',\n",
       " '\"']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tokenizer splits off punctuation marks as separate tokens.\n",
    "\n",
    "Now we can use another NLTK gadget called `ngrams`.  \"N-grams\" are the sequences that you get when you take overlapping chunks of N words at a time from a text.  NLTK's `ngrams` function takes two parameters: the list to get n-grams for, and the number of words to get.  It returns a generator object, whose exact nature we don't need to worry about for now.  Suffice it to say we can convert it to a list by passing it to `list()`.  We can see a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'house'),\n",
       " ('house', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'building'),\n",
       " ('building', 'that')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(toks, 2))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are **bigrams**: sequences of two words.  **Trigrams** would be sequences of three words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'house', 'is'),\n",
       " ('house', 'is', 'a'),\n",
       " ('is', 'a', 'building'),\n",
       " ('a', 'building', 'that'),\n",
       " ('building', 'that', 'is')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(toks, 3))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so on for different values of N giving different sizes of n-grams.\n",
    "\n",
    "(By the way, notice how I'm using indexing like `[:5]` to show only the first few elements of our results.  That is because the whole result is very long and I don't want to clutter up the notebook with gigantic output.  In your homework, if your results are too long to be displayed in full, you should do something similar.)\n",
    "\n",
    "We can use this `ngrams` function to start making some progress on our \"Bil dams\" task.  Let's iterate over the bigrams and make a list of just the ones that start with the word \"a\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['building', '\"', 'tent', 'caravan', 'short', 'home', '\"', 'connected', 'block', 'house', 'house', 'front', 'passage', 'roof', 'floor']\n"
     ]
    }
   ],
   "source": [
    "a_something = []\n",
    "for word1, word2 in nltk.ngrams(toks, 2):\n",
    "    if word1 == \"a\":\n",
    "        a_something.append(word2)\n",
    "print(a_something)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the word \"house\" appears twice in our list, because the phrase `a house` occurred twice in this text.  Notice also that there are some oddities, like quotation marks appearing, because the text contained things like `a \"permanent\" building` and, as we saw, NLTK splits off punctuation as separate tokens.  And if you look at a bit more of the data, you'll see that it considers things like \"A\" and 'a\" to be two different words, because they differ in case.  This is the sort of messiness we often have to deal with when processing language with computers.\n",
    "\n",
    "We can continue by counting up all those various words that follow \"a\".  To do this we can use the `Counter` class from the builtin `collections` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'building': 1,\n",
       "         '\"': 2,\n",
       "         'tent': 1,\n",
       "         'caravan': 1,\n",
       "         'short': 1,\n",
       "         'home': 1,\n",
       "         'connected': 1,\n",
       "         'block': 1,\n",
       "         'house': 2,\n",
       "         'front': 1,\n",
       "         'passage': 1,\n",
       "         'roof': 1,\n",
       "         'floor': 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counts = collections.Counter(a_something)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "\n",
    "Now your turn!  Make a list of all the words that follow the word \"is\" in this simple text.  Then make a Counter that counts how often each one occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously it would get pretty awkward to have to make separate variables called `a_something` and `is_something` and `the_something` and so on for every different word.  Instead, now try making one big dictionary, where the key is the first word (like \"a\" and \"is\" in the above examples) and the value is a list of all words that followed that word.  In other words your dictionary should wind up looking something like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"a\": ['building', '\"', 'tent', 'caravan', 'short', 'home', '\"', 'connected', 'block', 'house', 'house', 'front', 'passage', 'roof', 'floor'],\n",
    "    \"several\": [\"different\"],\n",
    "    # ... and so on\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try creating a slightly different data structure.  Instead of a dictionary with lists in it, we'll create a list with dictionaries in it.  Specifically, we want each entry in the list to be a dictionary with three entries for each n-gram in the corpus:\n",
    "\n",
    "1. `Size`: the length of the n-gram we are dealing with, but minus one (so if we look at bigrams `Size` should be 1, etc.)\n",
    "2. `Gram`: the n-gram itself, as a tuple, minus the last word\n",
    "    1. Note this will be a one-element tuple if we are dealing with bigrams\n",
    "3. `Word`: the last word of the n-gram\n",
    "\n",
    "In other words our list should look something like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"Size\": 1, \"Gram\": ('A',), \"Word\": \"house\"},\n",
    "    {\"Size\": 1, \"Gram\": ('house',), \"Word\": \"is\"},\n",
    "    {\"Size\": 1, \"Gram\": ('is',), \"Word\": \"a\"},\n",
    "]\n",
    "```\n",
    "\n",
    "First make such a dictionary for bigrams only (that is, all entries will have a `Size` of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a dictionary that contains all n-gram sizes from 1 up to 4.  (That means `Size` will go from 0 to 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's enough coding for now!  This may seem like a somewhat peculiar task, but next time we'll see how these data structures can be used to do something pretty cool.\n",
    "\n",
    "Finally, here are some of those old-fashioned things known as \"homework questions\".  Type your answers right here in the notebook.  You can either insert your answers in this same Markdown cell, or add separate Markdown cells below for each answer.  (If you do make separate cells, copy the text of the corresponding question into each cell so it's clear which question you're answering in each cell.)\n",
    "\n",
    "Your answers don't need to be long --- at most a few sentences per question, sometimes only a few words.  These questions are aimed at getting you to think about the utility of the computational techniques you've just been practicing.  Many qiestions will not have a single \"right answer\" (although there are many wrong answers to any question!).  Your answers should show that you've been paying attention to what you did here, and what we did in class, and are thinking about how these tools might be used to make computers do something with language.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What do you think n-grams might be good for?  Why might we want to make lists of the n-grams in a text, as we've been doing above?\n",
    "2. In the above exercises, we've sometimes been doing similar things in slightly different ways: a list here, then similar data packaged into dictionary form,   Why should we do this?  Why might we need to repackage the same data into different data structures?\n",
    "3. In some questions above, we used the `Counter` class from the `collections` module.\n",
    "    1. What does it do?\n",
    "    2. What type of data does it take as input?\n",
    "    3. What type of data does it produce as output?\n",
    "4. Go to the documentation at https://docs.python.org and go into \"Library Reference\".  Choose a class or function from either the `collections` or `itertools` module.\n",
    "    1. Which function/class did you choose?  Give a link to the documentation for it.\n",
    "    2. Describe in your own words what it does.\n",
    "    3. What type of data does it take as input?\n",
    "    4. What type of data does it produce as output?\n",
    "    5. Based on what you have read, do you think you would be able to make use of this function/class in your own code?  If so, when would you use it?  If not, why not?\n",
    "5. In doing this assignment, what was the most frustrating or difficult aspect?  What made it difficult, and what did you do to try to figure it out or get it to work?\n",
    "   \n",
    "Be sure to submit your notebook file on GauchoSpace to receive credit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
